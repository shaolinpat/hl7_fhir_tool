#!/usr/bin/env python3
"""
tools/hl7_stream_to_fhir.py

Read a stream of back-to-back HL7 v2 messages (e.g., generated by
scripts/generate_hl7_adt_a01_bulk.py), split on MSH boundaries,
route each message to the appropriate transformer, and emit FHIR
JSON resources as NDJSON (one JSON object per line).

This script is intentionally simple glue code. All domain-specific
mapping logic lives in the per-message transformers under
hl7_fhir_tool.transform.v2_to_fhir.
"""

from __future__ import annotations

import argparse
import json
import re
from pathlib import Path
from typing import Any, Dict, Iterable, List, Type

from hl7apy.parser import parse_message

from hl7_fhir_tool.transform.v2_to_fhir import adt_a01
from hl7_fhir_tool.transform.v2_to_fhir import adt_a03
from hl7_fhir_tool.transform.v2_to_fhir import adt_a08
from hl7_fhir_tool.transform.v2_to_fhir import orm_o01
from hl7_fhir_tool.transform.v2_to_fhir import oru_r01


TransformerClass = Type[Any]


DISPATCH: Dict[str, TransformerClass] = {
    "ADT^A01": adt_a01.ADTA01Transformer,
    "ADT^A03": adt_a03.ADTA03Transformer,
    "ADT^A08": adt_a08.ADTA08Transformer,
    "ORM^O01": orm_o01.ORMO01Transformer,
    "ORU^R01": oru_r01.ORUR01Transformer,
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Convert an HL7 v2 stream file into a FHIR NDJSON event stream "
            "by routing each message to the appropriate transformer."
        )
    )
    parser.add_argument(
        "--input",
        "--in",
        dest="input_path",
        type=Path,
        required=True,
        help=(
            "Path to the HL7 stream file " "(e.g. tests/data/hl7_stream/mixed_300.hl7)."
        ),
    )
    parser.add_argument(
        "--output",
        "--out",
        dest="output_path",
        type=Path,
        default=Path("outputs/fhir/fhir_events.jsonl"),
        help=(
            "Path to the FHIR NDJSON output file. "
            "Default: outputs/fhir/fhir_events.jsonl"
        ),
    )
    parser.add_argument(
        "--encoding",
        type=str,
        default="utf-8",
        help="File encoding for input HL7 stream. Default: utf-8.",
    )
    return parser.parse_args()


def load_stream(path: Path, encoding: str = "utf-8") -> str:
    """
    Load the HL7 stream as text.

    Any CRLF / CR line endings are normalized to LF for easier splitting.
    """
    text = path.read_text(encoding=encoding, errors="replace")
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    return text


def split_messages(stream_text: str) -> List[str]:
    """
    Split a back-to-back HL7 stream into individual messages.

    We split on MSH boundaries using a regex lookahead so that each
    message starts with 'MSH|'.

    The input is assumed to have one segment per line after normalization.
    """
    chunks = re.split(r"(?m)^(?=MSH\|)", stream_text)
    messages: List[str] = []
    for chunk in chunks:
        chunk = chunk.strip()
        if not chunk:
            continue
        messages.append(chunk)
    return messages


def normalize_message(hl7_text: str) -> str:
    """
    Normalize a single HL7 message to use CR ('\\r') as segment separator,
    as expected by many HL7 parsers and libraries.

    The input is assumed to have segments separated by LF ('\\n').
    """
    lines = [line.rstrip() for line in hl7_text.split("\n") if line.strip()]
    if not lines:
        return ""
    return "\r".join(lines) + "\r"


def get_message_type(hl7_message: str) -> str:
    """
    Extract MSH-9 (message type) from a normalized HL7 message.

    Returns values such as 'ADT^A03', 'ORU^R01', etc.
    """
    first_line = None
    for line in hl7_message.split("\r"):
        if line.strip():
            first_line = line
            break

    if first_line is None:
        raise ValueError("Empty HL7 message (no segments found).")

    fields = first_line.split("|")
    if len(fields) < 9:
        raise ValueError(f"MSH segment has fewer than 9 fields: {first_line!r}")

    return fields[8]


def transform_stream(
    messages: Iterable[str],
    dispatch: Dict[str, TransformerClass],
) -> Iterable[Any]:
    """
    Iterate over HL7 messages, route each one to the appropriate transformer,
    and yield FHIR resources.

    Each transformer class is expected to implement:

        .applies(self, msg: Message) -> bool
        .transform(self, msg: Message) -> List[Resource]
    """
    for idx, raw_msg in enumerate(messages, start=1):
        normalized = normalize_message(raw_msg)
        if not normalized:
            continue

        try:
            msg_type = get_message_type(normalized)
        except Exception as exc:
            print(f"[WARN] Skipping message {idx}: cannot determine type ({exc})")
            continue

        transformer_cls = dispatch.get(msg_type)
        if transformer_cls is None:
            print(
                f"[WARN] No transformer registered for message type {msg_type!r}; "
                f"skipping message {idx}."
            )
            continue

        try:
            msg_obj = parse_message(normalized)
            transformer = transformer_cls()
            resources = transformer.transform(msg_obj)
        except Exception as exc:
            print(
                f"[ERROR] Transformer for {msg_type!r} failed on message {idx}: {exc}"
            )
            continue

        if not resources:
            continue

        for resource in resources:
            yield resource


def write_ndjson(resources: Iterable[Any], output_path: Path) -> None:
    """
    Write FHIR resources as NDJSON (one JSON object per line).

    Resources may be pydantic models (from fhir.resources) or plain dicts.
    Any non-serializable type (date, datetime, Decimal, etc.) will be
    converted to a string.
    """

    def default_serializer(obj: Any) -> Any:
        # Convert dates, datetimes, Decimals, UUIDs, etc.
        try:
            return str(obj)
        except Exception:
            return f"<<nonserializable:{type(obj).__name__}>>"

    output_path.parent.mkdir(parents=True, exist_ok=True)

    with output_path.open("w", encoding="utf-8") as f:
        for resource in resources:

            # Convert pydantic models to dict
            if isinstance(resource, dict):
                data = resource
            elif hasattr(resource, "model_dump"):
                data = resource.model_dump(by_alias=True, exclude_none=True)
            elif hasattr(resource, "dict"):
                try:
                    data = resource.dict(by_alias=True, exclude_none=True)
                except TypeError:
                    data = resource.dict()
            else:
                # Fallback: try to serialize directly
                data = resource

            # Use default=str for unsupported types
            json.dump(data, f, ensure_ascii=False, default=default_serializer)
            f.write("\n")


# def write_ndjson(resources: Iterable[Any], output_path: Path) -> None:
#     """
#     Write FHIR resources as NDJSON (one JSON object per line).

#     Resources may be pydantic models (from fhir.resources) or plain dicts.
#     We attempt to call model_dump() (pydantic v2) or dict() (v1) if present.
#     """
#     output_path.parent.mkdir(parents=True, exist_ok=True)
#     with output_path.open("w", encoding="utf-8") as f:
#         for resource in resources:
#             if isinstance(resource, dict):
#                 data = resource
#             elif hasattr(resource, "model_dump"):
#                 data = resource.model_dump(by_alias=True, exclude_none=True)
#             elif hasattr(resource, "dict"):
#                 try:
#                     data = resource.dict(by_alias=True, exclude_none=True)
#                 except TypeError:
#                     data = resource.dict()
#             else:
#                 data = resource

#             json.dump(data, f, ensure_ascii=False)
#             f.write("\n")


def main() -> None:
    args = parse_args()
    stream_text = load_stream(args.input_path, encoding=args.encoding)
    messages = split_messages(stream_text)
    print(f"[INFO] Parsed {len(messages)} HL7 messages from {args.input_path}")

    resources = transform_stream(messages, DISPATCH)
    write_ndjson(resources, args.output_path)

    print(f"[INFO] Wrote FHIR NDJSON to {args.output_path}")


if __name__ == "__main__":
    main()
